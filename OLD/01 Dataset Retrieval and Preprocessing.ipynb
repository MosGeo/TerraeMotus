{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "These functions are used to obtain the data from the server using the Obspy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from obspy.taup import TauPyModel\n",
    "from obspy.geodetics import gps2dist_azimuth, kilometer2degrees\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define a retrieval function to be used for getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEvents(clientName, networkName,  stationName, startTime, endTime, minMagnitude, maxRadius):\n",
    "    '''\n",
    "    Obtain a catalog of the seismic events around the base station\n",
    "    '''\n",
    "    # Find the possible earthquakes and put them in a catalog\n",
    "    client = Client(clientName)\n",
    "    inventory = client.get_stations(network=networkName)# , station=stationName)\n",
    "    station = inventory[0][0]\n",
    "    cat = client.get_events(starttime=startTime, endtime=endTime, minmagnitude=minMagnitude, latitude=station.latitude, longitude=station.longitude, maxradius=maxRadius)\n",
    "    \n",
    "    return cat\n",
    "\n",
    "def getStreams(clientName, networkName,  stationNames, channelName, cat, timeBefore, timeAfter):\n",
    "    '''\n",
    "    Get the streams for the events (the seismic signal)\n",
    "    '''\n",
    "    # Get the stream for each event\n",
    "    model = TauPyModel(model=\"iasp91\")\n",
    "    client = Client(clientName)\n",
    "\n",
    "    \n",
    "    nEvents = len(cat)\n",
    "    print(\"Will analyze \" + str(nEvents) + \" events\")\n",
    "    stList = []\n",
    "    for i in range(0, nEvents):\n",
    "        for stationName in stationNames:\n",
    "            try:\n",
    "                inventory = client.get_stations(network=networkName, station=stationName)\n",
    "                station = inventory[0][0]\n",
    "                event = cat[i]\n",
    "                origin = event.origins[0]\n",
    "                distance, _, _ = gps2dist_azimuth(origin.latitude, origin.longitude, station.latitude, station.longitude)\n",
    "                distance = kilometer2degrees(distance / 1e3)\n",
    "                arrivals = model.get_travel_times(origin.depth / 1e3, distance)\n",
    "                traveltime = arrivals[0].time\n",
    "                arrival_time = origin.time + traveltime\n",
    "                # Get the earthquake signal and store its needed information\n",
    "                st = client.get_waveforms(network=networkName, station=stationName, location=\"00\", channel=channelName, starttime=arrival_time-timeBefore, endtime=arrival_time+timeAfter)\n",
    "                stList.append(st)\n",
    "                print(\"Got event \" + str(i) + \" in station \" + stationName)\n",
    "            except:\n",
    "                print(\"Could not get stream \" + str(i) + \" in station \" +  stationName)\n",
    "    return stList\n",
    "\n",
    "def getRandomStreams(clientName, networkName,  stationNames, channelName, timeBefore, timeAfter, starttime, endtime, nEvents = 1):\n",
    "    '''\n",
    "    Get the streams for the events for random singals (negative labels)\n",
    "    '''\n",
    "    client = Client(clientName)\n",
    "    \n",
    "    print(\"Will analyze \" + str(nEvents) + \" events\")\n",
    "    stList = []\n",
    "    for i in range(0, nEvents):\n",
    "        for stationName in stationNames:\n",
    "            try:\n",
    "                inventory = client.get_stations(network=networkName, station=stationName)\n",
    "                station = inventory[0][0]\n",
    "                arrival_time = startTime + (endTime - startTime) * np.random.random()\n",
    "                st = client.get_waveforms(network=networkName, station=stationName, location=\"00\", channel=channelNames, starttime=arrival_time-timeBefore, endtime=arrival_time+timeAfter)\n",
    "                stList.append(st)\n",
    "                print(\"Got random event \" + str(i) + \" in station \" + stationName)\n",
    "            except:\n",
    "                print(\"Could not get random stream \" + str(i) + \" in station \" +  stationName)\n",
    "    return stList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us make a function that save and load the list of seismogram. It is a list of objects so we have to use the package pickle which is included in python by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveList(listToSave, fileName = 'SavedList.dat'):\n",
    "    '''\n",
    "    Save a list into a file.\n",
    "    '''\n",
    "    pickle.dump( listToSave, open(fileName, \"wb\" ))\n",
    "\n",
    "\n",
    "def loadList(fileName):\n",
    "    '''\n",
    "    Load a list from a file\n",
    "    '''\n",
    "    loadedList = pickle.load( open( fileName, \"rb\" ))\n",
    "    return loadedList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define a function to extract the data to numpy format for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def st2numpy(st, traceNumber=0):\n",
    "    '''\n",
    "    Retrive information from the seismogram raw object\n",
    "    '''\n",
    "    trace = st.pop(traceNumber)\n",
    "    data = trace.data\n",
    "    time = trace.times('matplotlib')\n",
    "    return time, data\n",
    "\n",
    "def stList2numpy(stList, traceNumber=0, label=1):\n",
    "    '''\n",
    "    Retrive information from multiple seismograms and put them in an array\n",
    "    '''\n",
    "    nSt = len(stList)\n",
    "    timeList = []\n",
    "    dataList = []\n",
    "    labelList = []\n",
    "    \n",
    "    time, data = st2numpy(stList[0], traceNumber)\n",
    "    timeShape = time.shape\n",
    "    dataShape = data.shape\n",
    "    \n",
    "    timeList.append(time)\n",
    "    dataList.append(data)\n",
    "    labelList.append(label)\n",
    "    \n",
    "    for i in range(1, nSt):\n",
    "        time, data = st2numpy(stList[i], traceNumber)\n",
    "        if (data.shape == dataShape):\n",
    "            timeList.append(time)\n",
    "            dataList.append(data)\n",
    "            labelList.append(label)\n",
    "\n",
    "    \n",
    "    timeArray = np.asarray(timeList).T;\n",
    "    dataArray = np.asarray(dataList).T;\n",
    "    labelArray = np.asarray(labelList).T;\n",
    "    labelArray = labelArray[:,np.newaxis]\n",
    "\n",
    "    return timeArray, dataArray, labelArray\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataset\n",
    "Now, let us retrieve the dataset and save it. This is the actual script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 seismic events found\n"
     ]
    }
   ],
   "source": [
    "networkName      = \"BK\"                                # Seismic network name\n",
    "#stationNames      = [\"PKD\", \"BRK\", \"BDM\", \"WENL\"]      # Station names (first station is the base station)\n",
    "stationNames      = [\"TSCN\", \"PKD\", \"THIS\", \"RAMR\", \"TCHL\"]      # Station names (first station is the base station)\n",
    "\n",
    "clientName       = \"NCEDC\"                             # Client name (server)\n",
    "startTime        = UTCDateTime(\"2010-06-01\")           # Start time to look for data\n",
    "endTime          = UTCDateTime(\"2018-05-14\")           # End time to look for data \n",
    "maxRadius        = .12 # angle                          # Maximum radius (in angles) away from the base station\n",
    "minMagnitude     = 3                                  # Minimum seismic magnitude for teh event\n",
    "channelNames      = \"BH?\"#vertical                    # Channel name (LHZ: 1Hz; BHZ: 40 Hz)\n",
    "neg2pos = 1;                                          # Approximate negative to positive labels\n",
    "secWarning = 60                                       # Number of seconds for the warning period (before seismic event)\n",
    "secPrecurser = 60                                  # Number of seconds for teh seismic precurser signal \n",
    "\n",
    "# Obtain the siesmic events \n",
    "timeAfter  = -secWarning;     \n",
    "timeBefore = secWarning+secPrecurser;\n",
    "cat  = getEvents(clientName, networkName,  stationNames[0], startTime, endTime, minMagnitude, maxRadius)\n",
    "print(str(len(cat))+ \" seismic events found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will analyze 3 events\n",
      "Got event 0 in station TSCN\n",
      "Got event 0 in station PKD\n",
      "Got event 0 in station THIS\n",
      "Got event 0 in station RAMR\n",
      "Got event 0 in station TCHL\n",
      "Got event 1 in station TSCN\n",
      "Got event 1 in station PKD\n",
      "Got event 1 in station THIS\n",
      "Got event 1 in station RAMR\n",
      "Could not get stream 1 in station TCHL\n",
      "Could not get stream 2 in station TSCN\n",
      "Got event 2 in station PKD\n",
      "Could not get stream 2 in station THIS\n",
      "Got event 2 in station RAMR\n",
      "Could not get stream 2 in station TCHL\n",
      "Will analyze 2 events\n",
      "Got random event 0 in station TSCN\n",
      "Got random event 0 in station PKD\n",
      "Got random event 0 in station THIS\n",
      "Could not get random stream 0 in station RAMR\n",
      "Got random event 0 in station TCHL\n",
      "Got random event 1 in station TSCN\n",
      "Got random event 1 in station PKD\n",
      "Got random event 1 in station THIS\n",
      "Got random event 1 in station RAMR\n",
      "Got random event 1 in station TCHL\n"
     ]
    }
   ],
   "source": [
    "# get the data from the server\n",
    "stListPositives = getStreams(clientName, networkName,  stationNames, channelNames, cat, timeBefore, timeAfter)\n",
    "nNegatives = int(neg2pos * len(stListPositives) / len(stationNames))\n",
    "stListNegatives = getRandomStreams(clientName, networkName,  stationNames, channelNames, timeBefore, timeAfter, startTime, endTime, nNegatives)\n",
    "\n",
    "# save it in raw form (object: stream)\n",
    "attributeString = \"_M_\" + str(minMagnitude) + \"_R_\" + str(maxRadius) +  \"_S_\" + str(len(stationNames)) + \"_Sec_\" + str(secPrecurser)\n",
    "saveList(stListPositives, fileName = \"PositivesList_Test_\" + attributeString +  \".dat\")\n",
    "saveList(stListNegatives, fileName = \"NegativeList_Test_\" + attributeString +  \".dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stListPositives[0]\n",
    "timeArrayNeg, dataArrayNeg, labelArrayNeg = stList2numpy(copy.deepcopy(stListNegatives),0, label = 0)\n",
    "timeArrayPos, dataArrayPos, labelArrayPos = stList2numpy(copy.deepcopy(stListPositives),0, label = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the streams into numpy arrays\n",
    "timeArrayNeg1, dataArrayNeg1, labelArrayNeg1 = stList2numpy(copy.deepcopy(stListNegatives),0, label = 0)\n",
    "timeArrayPos1, dataArrayPos1, labelArrayPos1 = stList2numpy(copy.deepcopy(stListPositives),0, label = 1)\n",
    "\n",
    "timeArrayNeg2, dataArrayNeg2, labelArrayNeg2 = stList2numpy(copy.deepcopy(stListNegatives),1, label = 0)\n",
    "timeArrayPos2, dataArrayPos2, labelArrayPos2 = stList2numpy(copy.deepcopy(stListPositives),1, label = 1)\n",
    "\n",
    "timeArrayNeg3, dataArrayNeg3, labelArrayNeg3 = stList2numpy(copy.deepcopy(stListNegatives),2, label = 0)\n",
    "timeArrayPos3, dataArrayPos3, labelArrayPos3 = stList2numpy(copy.deepcopy(stListPositives),2, label = 1)\n",
    "\n",
    "# Concatinate positive and negative arrays\n",
    "#timeArrayNeg  = np.concatenate([timeArrayNeg1 , timeArrayNeg2, timeArrayNeg3], axis = 2);\n",
    "#timeArrayPos  = np.concatenate([timeArrayPos1 , timeArrayPos2, timeArrayPos3], axis = 2);\n",
    "\n",
    "dataArrayNeg  = np.stack([dataArrayNeg1 , dataArrayNeg2, dataArrayNeg3], axis = 2);\n",
    "dataArrayPos  = np.stack([dataArrayPos1 , dataArrayPos2, dataArrayPos3], axis = 2);\n",
    "\n",
    "#labelArrayNeg  = np.concatenate([labelArrayNeg1 , labelArrayNeg2, labelArrayNeg3], axis = 2);\n",
    "#labelArrayPos  = np.concatenate([labelArrayPos1 , labelArrayPos2, labelArrayPos3], axis = 2);\n",
    "\n",
    "\n",
    "# Concatinate positive and negative arrays\n",
    "time  = np.concatenate([timeArrayPos1 , timeArrayNeg1], axis = 1);\n",
    "data  = np.concatenate([dataArrayPos , dataArrayNeg], axis = 1);\n",
    "label = np.concatenate([labelArrayPos1 , labelArrayNeg1]);\n",
    "\n",
    "# Save numpy arrays for usage in the neural network\n",
    "np.save(\"TimeTest\" + attributeString + \".npy\", time)\n",
    "np.save(\"DataTest\" + attributeString + \".npy\", data)\n",
    "np.save(\"LabelTest\" + attributeString + \".npy\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just to make sure, Let's plot some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "fig = plt.figure()\n",
    "plt.plot(timeArrayNeg[:,i], dataArrayNeg[:,i])\n",
    "fig = plt.figure()\n",
    "plt.plot(timeArrayPos[:,i], dataArrayPos[:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are based on Obspy internal functions\n",
    "\n",
    "import math as M\n",
    "from matplotlib import mlab\n",
    "from matplotlib.colors import Normalize\n",
    "from obspy.imaging.cm import obspy_sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "def getSpectogram(data, samp_rate, per_lap=0.9, wlen=None, log=False,\n",
    "                outfile=None, fmt=None, axes=None, dbscale=False,\n",
    "                mult=8.0, zorder=None, title=None,\n",
    "                show=True, sphinx=False, clip=[0.0, 1.0]):\n",
    "    \n",
    "    # enforce float for samp_rate\n",
    "    samp_rate = float(samp_rate)\n",
    "\n",
    "    # set wlen from samp_rate if not specified otherwise\n",
    "    if not wlen:\n",
    "        wlen = samp_rate / 100.\n",
    "\n",
    "    npts = len(data)\n",
    "    # nfft needs to be an integer, otherwise a deprecation will be raised\n",
    "    # XXX add condition for too many windows => calculation takes for ever\n",
    "    nfft = int(_nearest_pow_2(wlen * samp_rate))\n",
    "    if nfft > npts:\n",
    "        nfft = int(_nearest_pow_2(npts / 8.0))\n",
    "\n",
    "    if mult is not None:\n",
    "        mult = int(_nearest_pow_2(mult))\n",
    "        mult = mult * nfft\n",
    "    nlap = int(nfft * float(per_lap))\n",
    "\n",
    "    data = data - data.mean()\n",
    "    end = npts / samp_rate\n",
    "\n",
    "    \n",
    "    specgram, freq, time = mlab.specgram(data, Fs=samp_rate, NFFT=nfft,\n",
    "                                         pad_to=mult, noverlap=nlap)\n",
    "    # db scale and remove zero/offset for amplitude\n",
    "    if dbscale:\n",
    "        specgram = 10 * np.log10(specgram[1:, :])\n",
    "    else:\n",
    "        specgram = np.sqrt(specgram[1:, :])\n",
    "    freq = freq[1:]\n",
    "\n",
    "    vmin, vmax = clip\n",
    "    if vmin < 0 or vmax > 1 or vmin >= vmax:\n",
    "        msg = \"Invalid parameters for clip option.\"\n",
    "        raise ValueError(msg)\n",
    "    _range = float(specgram.max() - specgram.min())\n",
    "    vmin = specgram.min() + vmin * _range\n",
    "    vmax = specgram.min() + vmax * _range\n",
    "    norm = Normalize(vmin, vmax, clip=True)\n",
    "    \n",
    "    return specgram, freq, time\n",
    "\n",
    "\n",
    "def _nearest_pow_2(x):\n",
    "    \"\"\"\n",
    "    Find power of two nearest to x\n",
    "\n",
    "    >>> _nearest_pow_2(3)\n",
    "    2.0\n",
    "    >>> _nearest_pow_2(15)\n",
    "    16.0\n",
    "\n",
    "    :type x: float\n",
    "    :param x: Number\n",
    "    :rtype: Int\n",
    "    :return: Nearest power of 2 to x\n",
    "    \"\"\"\n",
    "    a = M.pow(2, M.ceil(np.log2(x)))\n",
    "    b = M.pow(2, M.floor(np.log2(x)))\n",
    "    if abs(a - x) < abs(b - x):\n",
    "        return a\n",
    "    else:\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some data and plot the spectogram\n",
    "data  = np.load(\"Datasets\\Data_M_2.8_R_0.5_S_4_Sec_256.npy\")\n",
    "label = np.load(\"Datasets\\Label_M_2.8_R_0.5_S_4_Sec_256.npy\")\n",
    "time  = np.load(\"Datasets\\Time_M_2.8_R_0.5_S_4_Sec_256.npy\")\n",
    "\n",
    "data  = np.load(\"Datasets\\DataExamples.npy\")\n",
    "label = np.load(\"Datasets\\LabelExamples.npy\")\n",
    "time  = np.load(\"Datasets\\TimeExamples.npy\")\n",
    "\n",
    "i = 3\n",
    "\n",
    "specgram, freq, time = getSpectogram(data[:,i], 40)\n",
    "specgram = np.log10(specgram)\n",
    "newSize = np.round(np.array(specgram.shape) *.1)\n",
    "#specgram = resize(specgram,[64,64])\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(5, 4), dpi=100)\n",
    "plt.imshow(specgram, extent=[np.min(time),np.max(time)    ,np.max(freq),np.min(freq)])\n",
    "plt.gca().set_aspect(10)\n",
    "plt.gca().invert_yaxis()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way of plotting the spectogram (using the built in function of Obspy)\n",
    "stListPositives  = np.load(\"Raw Data\\PositivesList__M_2.8_R_0.5_S_4_Sec_256.dat\")\n",
    "stListPositives[1].spectrogram()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
